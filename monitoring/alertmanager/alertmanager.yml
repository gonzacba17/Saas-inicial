global:
  # SMTP configuration for email alerts
  smtp_smarthost: '${SMTP_HOST:-smtp.gmail.com:587}'
  smtp_from: '${ALERT_EMAIL_FROM:-alerts@saascafeterias.com}'
  smtp_auth_username: '${SMTP_USERNAME}'
  smtp_auth_password: '${SMTP_PASSWORD}'
  smtp_require_tls: true

  # Slack webhook URL
  slack_api_url: '${SLACK_WEBHOOK_URL}'

  # PagerDuty integration key
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

# Templates for notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Routing tree
route:
  # Default route
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 5m
  repeat_interval: 12h
  receiver: 'default-receiver'
  
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 5m
      routes:
        # Database issues - notify DBA team
        - match_re:
            alertname: 'DatabaseConnectionHigh|DatabaseSlowQueries'
          receiver: 'dba-team'
        
        # Security issues - notify security team
        - match_re:
            alertname: 'SuspiciousActivity|HighAuthFailureRate'
          receiver: 'security-team'
        
        # Payment issues - notify payments team
        - match_re:
            alertname: 'PaymentFailures'
          receiver: 'payments-team'

    # Warning alerts - less urgent
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_interval: 10m
      repeat_interval: 4h

    # Info alerts - business metrics
    - match:
        severity: info
      receiver: 'business-team'
      repeat_interval: 24h

    # Night mode - suppress non-critical alerts during off-hours
    - match:
        severity: warning
      receiver: 'night-mode'
      active_time_intervals:
        - night-hours

# Time intervals
time_intervals:
  - name: night-hours
    time_intervals:
      - times:
          - start_time: '22:00'
            end_time: '08:00'
        days_of_month: ['1:31']

# Receivers (notification channels)
receivers:
  # Default receiver
  - name: 'default-receiver'
    email_configs:
      - to: '${DEFAULT_EMAIL:-devops@saascafeterias.com}'
        subject: 'SaaS Cafeter√≠as Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Instance: {{ .Labels.instance }}
          {{ end }}

  # Critical alerts - multiple channels
  - name: 'critical-alerts'
    email_configs:
      - to: '${CRITICAL_EMAIL:-critical@saascafeterias.com}'
        subject: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'
        body: |
          üö® CRITICAL ALERT üö®
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Instance: {{ .Labels.instance }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          
          Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
    
    slack_configs:
      - channel: '#critical-alerts'
        title: 'üö® Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          
          *Severity:* {{ .Labels.severity }}
          *Instance:* {{ .Labels.instance }}
          {{ if .Annotations.runbook_url }}
          *Runbook:* {{ .Annotations.runbook_url }}
          {{ end }}
          {{ end }}
        send_resolved: true
    
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_ROUTING_KEY}'
        description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'
          
  # Warning alerts
  - name: 'warning-alerts'
    email_configs:
      - to: '${WARNING_EMAIL:-warnings@saascafeterias.com}'
        subject: '‚ö†Ô∏è Warning: {{ .GroupLabels.alertname }}'
        body: |
          ‚ö†Ô∏è WARNING ALERT ‚ö†Ô∏è
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Instance: {{ .Labels.instance }}
          {{ end }}
    
    slack_configs:
      - channel: '#warnings'
        title: '‚ö†Ô∏è Warning: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          {{ .Annotations.summary }}
          {{ .Annotations.description }}
          {{ end }}
        send_resolved: true

  # DBA team for database issues
  - name: 'dba-team'
    email_configs:
      - to: '${DBA_EMAIL:-dba@saascafeterias.com}'
        subject: 'üóÑÔ∏è Database Alert: {{ .GroupLabels.alertname }}'
        body: |
          üóÑÔ∏è DATABASE ALERT üóÑÔ∏è
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          {{ end }}
    
    slack_configs:
      - channel: '#database-alerts'
        title: 'üóÑÔ∏è Database Alert: {{ .GroupLabels.alertname }}'

  # Security team
  - name: 'security-team'
    email_configs:
      - to: '${SECURITY_EMAIL:-security@saascafeterias.com}'
        subject: 'üîí Security Alert: {{ .GroupLabels.alertname }}'
        body: |
          üîí SECURITY ALERT üîí
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
          
          This requires immediate investigation.
    
    slack_configs:
      - channel: '#security-alerts'
        title: 'üîí Security Alert: {{ .GroupLabels.alertname }}'
        color: 'danger'
    
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_SECURITY_KEY}'
        description: 'Security Alert: {{ .CommonAnnotations.summary }}'

  # Payments team
  - name: 'payments-team'
    email_configs:
      - to: '${PAYMENTS_EMAIL:-payments@saascafeterias.com}'
        subject: 'üí≥ Payment Alert: {{ .GroupLabels.alertname }}'
        body: |
          üí≥ PAYMENT SYSTEM ALERT üí≥
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          {{ end }}
    
    slack_configs:
      - channel: '#payments-alerts'
        title: 'üí≥ Payment Alert: {{ .GroupLabels.alertname }}'

  # Business team - for KPI alerts
  - name: 'business-team'
    email_configs:
      - to: '${BUSINESS_EMAIL:-business@saascafeterias.com}'
        subject: 'üìä Business Metric Alert: {{ .GroupLabels.alertname }}'
        body: |
          üìä BUSINESS METRICS ALERT üìä
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
    
    slack_configs:
      - channel: '#business-metrics'
        title: 'üìä Business Alert: {{ .GroupLabels.alertname }}'

  # Night mode - reduced notifications
  - name: 'night-mode'
    email_configs:
      - to: '${ONCALL_EMAIL:-oncall@saascafeterias.com}'
        subject: 'üåô Night Alert: {{ .GroupLabels.alertname }}'
        body: |
          üåô NIGHT MODE ALERT üåô
          
          {{ range .Alerts }}
          Summary: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
          
          This alert was suppressed during night hours but is now being reported.

# Inhibition rules - suppress certain alerts when others are firing
inhibit_rules:
  # Suppress warning alerts when critical alerts for the same service are firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
  
  # Suppress individual service alerts when general service down alert is firing
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: 'HighErrorRate|HighResponseTime|DatabaseConnectionHigh'
    equal: ['instance']
  
  # Suppress memory alerts when disk is critical (likely same issue)
  - source_match:
      alertname: 'DiskSpaceCritical'
    target_match:
      alertname: 'HighMemoryUsage'
    equal: ['instance']